\section{Classifying $\gamma$-ray bursts}

Logistic regression is a way to classify data given some already labelled data. In this exercise, long $\gamma$-ray bursts are classified according to their certain characteristics other than time it has been observed. $\gamma$ ray bursts are classified as short or long based on their time scale. If the burst has been received for over 10 seconds, then it is identified as a long $\gamma$ ray burst. The dataset that was given contains multiple gamma ray bursts where the time within which the detector receives $90\%$ of the $\gamma$-rays is given. In addition, some other properties of the host galaxy were given, such as the redshift. In this exercise, logistic regression is used to determine whether we deal with a long or short GRB (Gamma Ray Burst) depending on some of the characteristics of the host galaxy. The data given contains a lot of missing data. To correct for this, we first set all the missing data (data elements that have value -1) to 0. However, two columns are in log-space. The exponent of these elements in these columns are first taken. All the data that now corresponds to $\exp(-1)$ is set to 0. The final two columns are not considered in the train set because these contain too many missing data elements. In the first column there were some names that did not correspond to the GRB name (XRF). Just to be sure not to use data that is not representative, these rows were taken out of the train data. The labels are created by looping over the some rows but now for the third column that contains the time within which the detector receives $90\%$ of the $\gamma$-rays, $T_{90}$. If it is higher or equal to 10, then the label is set to 1, otherwise it is set to 0. Now that the data is complete, logistic regression is used to predict the labels with the use of the given characteristics.\footnote{Since this was the last exercise that I had to do, I unfortunately have no time left to explain exactly how logistic regression works.} The code that is used for this question is shown below,

\lstinputlisting{Q6.py}
The output of the code is a histogram that contains the predicted labels and the actual labels. 

\begin{figure}[h]
\centering
\includegraphics[scale=0.6]{plots/logistic_regression.png}
\caption{A histogram of the predicted labels (orange) vs. the actual labels (blue), where the predicted labels were obtained with the use of logisitc regression.}
\end{figure}

The histograms show that the logistic has done an adequate job, although it has still mislabelled quite some data. The accuracy that was obtained was $80\%$. However, there were some strange things happening while running the program. First of all, the number of epochs that have been used was only 2, which is quite unlikely if the logistic regression had done a good job. The reason for this is because many of the predicted labels were straight away set to 1. In the loss function this will go wrong since $\log(0)$ is not defined. Therefore, an extra term of 0.0001 was added to make sure that no nans were returned in this part of the run. This is not a nice way to do it, however, I just didn't manage to get it work otherwise. It could be that I have made a small mistake in the code where I add/multiply in the wrong way. Unfortunately, I could not find this mistake. Another explanation could be that I did not prepare my data well enough. A solution for this in the future would be to first check if I expect some correlation between columns beforehand before selecting the data. All in all, the logistic regression that I used did manage to overpass the baseline of $77.8\%$.\footnote{Sice $77.8\%$ of the data is equal to a long, setting all the predicted labels to long would result in an accuracy of $77.8\%$.} The question remains where in the algorithm it goes wrong.